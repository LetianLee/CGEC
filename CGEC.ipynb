{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中文语法纠错 Chinese Grammatical Error Correction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 项目介绍：\n",
    "* 本教程将演示：如何训练一个简单的中文语法纠错模型。<br>\n",
    "* 基于 BERT 预训练模型。<br>\n",
    "* 将会使用到 PyTorch 深度学习框架，以及 Hugging Face 提供的 Transformers 库。<br>\n",
    " \n",
    "#### 任务目标：\n",
    "纠正中文语句中的语法错误。\n",
    "\n",
    "*示例：*  \n",
    "> 原句：今天大阳很好，新情也很不错。所以我因该出门散不嘛？  \n",
    "> 纠正：今天太阳很好，心情也很不错。所以我应该出门散步吗？ \n",
    "\n",
    "#### 解决步骤:\n",
    "\n",
    "1. 准备工作  \n",
    "2. 加载数据\n",
    "3. 加载模型和优化器  \n",
    "4. 训练模型 \n",
    "5. 测试效果 \n",
    "\n",
    "\n",
    "<!-- 注意：  \n",
    "1.  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置使用数据集条数\n",
    "num = None   # 使用全部数据集\n",
    "# num = 50000  # 只使用前 num 条数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CscDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = json.load(open(file_path, 'r', encoding='utf-8'))[:num]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]['original_text'], self.data[index]['correct_text']\n",
    "\n",
    "\n",
    "def make_loaders(train_path='', valid_path='', test_path='', batch_size=32):\n",
    "    train_loader = None\n",
    "    if train_path and os.path.exists(train_path):\n",
    "        train_loader = DataLoader(CscDataset(train_path),\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=False,\n",
    "                                 )\n",
    "    valid_loader = None\n",
    "    if valid_path and os.path.exists(valid_path):\n",
    "        valid_loader = DataLoader(CscDataset(valid_path),\n",
    "                                  batch_size=batch_size,\n",
    "                                 )\n",
    "    test_loader = None\n",
    "    if test_path and os.path.exists(test_path):\n",
    "        test_loader = DataLoader(CscDataset(test_path),\n",
    "                                 batch_size=batch_size,\n",
    "                                )\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7870"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据\n",
    "train_loader, valid_loader, test_loader = make_loaders(train_path=\"output/train.json\",\n",
    "                                                       valid_path=\"output/dev.json\", \n",
    "                                                       test_path=\"output/test.json\",\n",
    "                                                       batch_size=32, \n",
    "                                                      )\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "from transformers import BertForMaskedLM\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-chinese')\n",
    "model.to(device)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载优化器\n",
    "from transformers import AdamW\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载分词器\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型 (Fine-tune BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7870/7870 [35:51<00:00,  3.66it/s, Loss=0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7870/7870 [36:33<00:00,  3.59it/s, Loss=0.005]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7870/7870 [36:10<00:00,  3.63it/s, Loss=0.007]  \n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "epoch = 3\n",
    "\n",
    "model.train()\n",
    "for epoch_i in range(epoch):\n",
    "    print('Epoch %s/%s' % (epoch_i + 1, epoch))\n",
    "    time.sleep(0.3)\n",
    "    \n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch in pbar:\n",
    "        optim.zero_grad()\n",
    "        ori_text, cor_text = batch\n",
    "        encoded_text = tokenizer(ori_text, padding=True, return_tensors='pt').to(device)\n",
    "        text_labels = tokenizer(cor_text, padding=True, return_tensors='pt')['input_ids'].to(device)\n",
    "        outputs = model(**encoded_text, labels=text_labels)\n",
    "        loss = outputs['loss']\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        # 显示进度条中的指标\n",
    "        pbar.set_postfix({\n",
    "            'Loss': '{:.3f}'.format(loss.item()),\n",
    "        })\n",
    "        \n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 0 轮纠错：今天大阳很好，新情也很不错。所以我因该出门散不嘛？\n",
      "第 1 轮纠错：今天太阳很好，心情也很不错。所以我应该出门散步嘛？\n",
      "第 2 轮纠错：今天太阳很好，心情也很不错。所以我应该出门散步嘛？\n",
      "第 3 轮纠错：今天太阳很好，心情也很不错。所以我应该出门散步嘛？\n"
     ]
    }
   ],
   "source": [
    "input = \"今天大阳很好，新情也很不错。所以我因该出门散不嘛？\"\n",
    "model.eval()\n",
    "for i in range(4):\n",
    "    print(\"第 %s 轮纠错：%s\" % (str(i),input))\n",
    "    input = tokenizer(input, padding=True, return_tensors='pt').to(device)\n",
    "    out = model(**input)\n",
    "    input = tokenizer.decode(torch.argmax(out.logits[0], dim=-1), skip_special_tokens=True).replace(' ', '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
